# app/tasks/generate_frequency.py

import logging
from datetime import datetime
import concurrent.futures
import time

from app.utils.date import get_today_kst
from app.utils.dynamo import (
    save_frequency_summary,
    get_frequency_by_category_and_date,
    get_news_by_category_and_date,
    update_news_card_content,
)
from app.services.openai_service import summarize_articles, cluster_similar_texts, summarize_group
from app.services.tts_service import text_to_speech
from app.utils.s3 import upload_audio_to_s3_presigned
from app.constants.category_map import CATEGORY_MAP
from app.services.deepsearch_service import extract_content_flexibly

# ë¡œê·¸ ì„¤ì •
logger = logging.getLogger()
logger.setLevel(logging.INFO)

def process_single_category(category_ko: str, date: str) -> dict:
    """
    ë‹¨ì¼ ì¹´í…Œê³ ë¦¬ ì²˜ë¦¬ í•¨ìˆ˜ (ë³‘ë ¬ ì²˜ë¦¬ìš©)
    """
    category_en = CATEGORY_MAP[category_ko]["api_name"]
    freq_id = f"{category_en}#{date}"
    start_time = time.time()
    
    try:
        # ì¤‘ë³µ ë°©ì§€: ì´ë¯¸ ìƒì„±ëœ ê²½ìš° ìŠ¤í‚µ
        if get_frequency_by_category_and_date(category_en, date):
            logger.info(f"ğŸš« ì´ë¯¸ ìƒì„±ë¨ â†’ ìŠ¤í‚µ: {freq_id}")
            return {"category": category_en, "status": "skipped", "reason": "already_exists"}

        logger.info(f"ğŸ”„ [{category_en}] ëŒ€ë³¸/ìŒì„± ìƒì„± ì‹œì‘")

        # í•´ë‹¹ ì¹´í…Œê³ ë¦¬ì˜ ì˜¤ëŠ˜ ê¸°ì‚¬ ë¶ˆëŸ¬ì˜¤ê¸°
        articles = get_news_by_category_and_date(category_en, date)
        logger.info(f"ğŸ“¥ [{category_en}] ìˆ˜ì§‘ëœ ê¸°ì‚¬ ìˆ˜: {len(articles)}")

        full_contents = []
        processed_count = 0
        target_count = 30  # ì •í™•íˆ 30ê°œë¡œ ì œí•œ

        # ê¸°ì‚¬ ë³¸ë¬¸ ì •í™•íˆ 30ê°œê¹Œì§€ ìˆ˜ì§‘
        for i, article in enumerate(articles):
            if len(full_contents) >= target_count:
                logger.info(f"ğŸ¯ [{category_en}] ëª©í‘œ ë‹¬ì„±: {target_count}ê°œ ìˆ˜ì§‘ ì™„ë£Œ")
                break
                
            processed_count += 1
            news_id = article.get("news_id")
            url = article.get("content_url")
            content = article.get("content", "").strip()

            if not news_id or not url:
                logger.warning(f"âš ï¸ [{category_en}] #{processed_count} URL ë˜ëŠ” ID ì—†ìŒ â†’ ìŠ¤í‚µ")
                continue

            # ë³¸ë¬¸ì´ ì§§ê±°ë‚˜ ì—†ìœ¼ë©´ ì¬ì¶”ì¶œ ì‹œë„
            if not content or len(content) < 300:
                try:
                    content = extract_content_flexibly(url)
                    if content and len(content) >= 300:
                        update_news_card_content(news_id, content)
                        logger.info(f"â™»ï¸ [{category_en}] #{processed_count} ë³¸ë¬¸ ë³´ì™„ ì €ì¥ ì™„ë£Œ ({len(content)}ì)")
                    else:
                        logger.warning(f"âš ï¸ [{category_en}] #{processed_count} ë³¸ë¬¸ ì¶”ì¶œ ì‹¤íŒ¨ ë˜ëŠ” ë„ˆë¬´ ì§§ìŒ â†’ ìŠ¤í‚µ")
                        continue
                except Exception as e:
                    logger.warning(f"âŒ [{category_en}] #{processed_count} ë³¸ë¬¸ ì¬ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜: {e}")
                    continue

            # ğŸ”§ í† í° ìµœì í™”: 3000ì â†’ 1500ìë¡œ ë‹¨ì¶•
            trimmed = content[:1500]
            full_contents.append(trimmed)
            logger.info(f"âœ… [{category_en}] #{len(full_contents)} ë³¸ë¬¸ ì‚¬ìš© ì™„ë£Œ ({len(trimmed)}ì)")

        logger.info(f"ğŸ“Š [{category_en}] ìµœì¢… ìˆ˜ì§‘ëœ ê¸°ì‚¬ ìˆ˜: {len(full_contents)}ê°œ (ëª©í‘œ: {target_count}ê°œ)")

        # ë³¸ë¬¸ ìˆ˜ê°€ ë„ˆë¬´ ì ìœ¼ë©´ ìŠ¤í‚µ
        if len(full_contents) < 5:
            logger.warning(f"âš ï¸ [{category_en}] ìœ íš¨ ë³¸ë¬¸ ë¶€ì¡± ({len(full_contents)}ê°œ) â†’ ìŠ¤í‚µ")
            return {"category": category_en, "status": "failed", "reason": "insufficient_content"}

        # â­ï¸ [1ì°¨ í´ëŸ¬ìŠ¤í„°ë§] ì›ë³¸ ê¸°ì‚¬ ë³¸ë¬¸ ê¸°ë°˜ ë¬¼ë¦¬ì  ì¤‘ë³µ ì œê±°
        logger.info(f"ğŸ”„ [{category_en}] 1ì°¨ í´ëŸ¬ìŠ¤í„°ë§ ì‹œì‘: {len(full_contents)}ê°œ ê¸°ì‚¬")
        try:
            groups = cluster_similar_texts(full_contents, threshold=0.80)
            group_summaries = []
            
            for group_idx, group in enumerate(groups):
                if len(group) == 1:
                    # ë‹¨ì¼ ê¸°ì‚¬ëŠ” ê·¸ëŒ€ë¡œ ì‚¬ìš©
                    group_summaries.append(group[0])
                    logger.info(f"ğŸ“„ [{category_en}] ê·¸ë£¹ #{group_idx+1}: ë‹¨ì¼ ê¸°ì‚¬ ({len(group[0])}ì)")
                else:
                    # ì—¬ëŸ¬ ìœ ì‚¬ ê¸°ì‚¬ â†’ ëŒ€í‘œ ìš”ì•½ë¬¸ ìƒì„±
                    try:
                        summary = summarize_group(group, category_en)
                        group_summaries.append(summary)
                        logger.info(f"ğŸ“Š [{category_en}] ê·¸ë£¹ #{group_idx+1}: {len(group)}ê°œ ê¸°ì‚¬ â†’ í†µí•© ìš”ì•½ ({len(summary)}ì)")
                    except Exception as e:
                        logger.warning(f"âš ï¸ [{category_en}] ê·¸ë£¹ #{group_idx+1} ìš”ì•½ ì‹¤íŒ¨, ì²« ë²ˆì§¸ ê¸°ì‚¬ ì‚¬ìš©: {e}")
                        group_summaries.append(group[0])
            
            logger.info(f"âœ… [{category_en}] 1ì°¨ í´ëŸ¬ìŠ¤í„°ë§ ì™„ë£Œ: {len(full_contents)}ê°œ â†’ {len(group_summaries)}ê°œ ê·¸ë£¹")
            final_contents = group_summaries
            
        except Exception as e:
            logger.warning(f"âš ï¸ [{category_en}] 1ì°¨ í´ëŸ¬ìŠ¤í„°ë§ ì‹¤íŒ¨, ì›ë³¸ ê¸°ì‚¬ ì‚¬ìš©: {e}")
            final_contents = full_contents

        # GPTë¡œ ì¢…í•© ìŠ¤í¬ë¦½íŠ¸ ìƒì„± (2ì°¨ í´ëŸ¬ìŠ¤í„°ë§ í¬í•¨)
        logger.info(f"ğŸ“ [{category_en}] ëŒ€ë³¸ ìƒì„± ì‹œì‘: {len(final_contents)}ê°œ ê¸°ì‚¬")
        script = summarize_articles(final_contents, category_en)
        if not script or len(script) < 500:
            logger.warning(f"âš ï¸ [{category_en}] ìš”ì•½ ê¸¸ì´ ë¶€ì¡± â†’ ìŠ¤í‚µ")
            return {"category": category_en, "status": "failed", "reason": "summary_too_short"}

        logger.info(f"ğŸ“ [{category_en}] ìš”ì•½ ì™„ë£Œ: {len(script)}ì")

        # ElevenLabsë¡œ TTS ë³€í™˜ â†’ S3 Presigned URL ìƒì„±
        try:
            audio_bytes = text_to_speech(script)
            audio_url = upload_audio_to_s3_presigned(
                file_bytes=audio_bytes,
                user_id="shared",
                category=category_en,
                date=date,
                expires_in_seconds=604800  # ğŸ”§ Presigned URL 7ì¼ ìœ íš¨ (24ì‹œê°„ â†’ 7ì¼)
            )
            logger.info(f"ğŸ”Š [{category_en}] TTS Presigned URL ìƒì„± ì™„ë£Œ")
        except Exception as e:
            logger.warning(f"âŒ [{category_en}] TTS ì—…ë¡œë“œ ì‹¤íŒ¨: {str(e)}")
            return {"category": category_en, "status": "failed", "reason": f"tts_failed: {str(e)}"}

        # ê²°ê³¼ DynamoDBì— ì €ì¥
        item = {
            "frequency_id": freq_id,
            "category": category_en,
            "date": date,
            "script": script,
            "audio_url": audio_url,
            "created_at": datetime.utcnow().isoformat()
        }

        save_frequency_summary(item)
        
        elapsed_time = time.time() - start_time
        logger.info(f"âœ… [{category_en}] DynamoDB ì €ì¥ ì™„ë£Œ (ì†Œìš”ì‹œê°„: {elapsed_time:.1f}ì´ˆ)")
        
        return {
            "category": category_en, 
            "status": "success", 
            "script_length": len(script),
            "elapsed_time": elapsed_time
        }

    except Exception as e:
        elapsed_time = time.time() - start_time
        logger.exception(f"âŒ [{category_en}] ì²˜ë¦¬ ì‹¤íŒ¨ (ì†Œìš”ì‹œê°„: {elapsed_time:.1f}ì´ˆ): {str(e)}")
        return {
            "category": category_en, 
            "status": "failed", 
            "reason": f"exception: {str(e)}",
            "elapsed_time": elapsed_time
        }

def generate_all_frequencies():
    """
    âœ… ë§¤ì¼ ì˜¤ì „ 6ì‹œ ìë™ ì‹¤í–‰: ì¹´í…Œê³ ë¦¬ë³„ ë‰´ìŠ¤ ë³¸ë¬¸ ê¸°ë°˜ ê³µìœ  ëŒ€ë³¸/ìŒì„± ìƒì„± (ë³‘ë ¬ ì²˜ë¦¬)
    - ë‰´ìŠ¤ì¹´ë“œ DBì—ì„œ ì¹´í…Œê³ ë¦¬ë³„ ê¸°ì‚¬ ì •í™•íˆ 30ê°œ ì‚¬ìš© (í† í° ìµœì í™”)
    - ë¶€ì¡±í•œ ë³¸ë¬¸ì€ ì¬ì¶”ì¶œ
    - GPT ìš”ì•½í•˜ì—¬ ìŠ¤í¬ë¦½íŠ¸ ìƒì„± (í´ëŸ¬ìŠ¤í„°ë§ í¬í•¨)
    - ElevenLabs TTSë¡œ ë³€í™˜ í›„ S3 ì—…ë¡œë“œ
    - Frequencies í…Œì´ë¸”ì— ì €ì¥ (ìŠ¤í¬ë¦½íŠ¸ + Presigned MP3 ë§í¬)
    """
    date = get_today_kst()
    all_categories = list(CATEGORY_MAP.keys())
    total_start_time = time.time()
    
    logger.info(f"ğŸš€ ë³‘ë ¬ ì²˜ë¦¬ ì‹œì‘: {len(all_categories)}ê°œ ì¹´í…Œê³ ë¦¬ ë™ì‹œ ì²˜ë¦¬")
    logger.info(f"ğŸ“‹ ì¹´í…Œê³ ë¦¬ ëª©ë¡: {all_categories}")

    # ğŸš€ ë³‘ë ¬ ì²˜ë¦¬: ThreadPoolExecutor ì‚¬ìš©
    results = []
    with concurrent.futures.ThreadPoolExecutor(max_workers=5) as executor:  # 5ê°œ ë™ì‹œ ì²˜ë¦¬
        # ê° ì¹´í…Œê³ ë¦¬ë¥¼ ë³‘ë ¬ë¡œ ì²˜ë¦¬í•˜ëŠ” Future ê°ì²´ ìƒì„±
        future_to_category = {
            executor.submit(process_single_category, category_ko, date): category_ko 
            for category_ko in all_categories
        }
        
        # ì™„ë£Œëœ ìˆœì„œëŒ€ë¡œ ê²°ê³¼ ìˆ˜ì§‘
        for future in concurrent.futures.as_completed(future_to_category):
            category_ko = future_to_category[future]
            try:
                result = future.result()
                results.append(result)
                
                if result["status"] == "success":
                    logger.info(f"ğŸ‰ [{result['category']}] ì„±ê³µ ì™„ë£Œ - ëŒ€ë³¸: {result['script_length']}ì, ì†Œìš”ì‹œê°„: {result['elapsed_time']:.1f}ì´ˆ")
                elif result["status"] == "skipped":
                    logger.info(f"â­ï¸ [{result['category']}] ìŠ¤í‚µë¨ - ì‚¬ìœ : {result['reason']}")
                else:
                    logger.warning(f"âš ï¸ [{result['category']}] ì‹¤íŒ¨ - ì‚¬ìœ : {result['reason']}")
                    
            except Exception as exc:
                logger.exception(f"âŒ [{category_ko}] ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: {exc}")
                results.append({
                    "category": CATEGORY_MAP[category_ko]["api_name"], 
                    "status": "failed", 
                    "reason": f"executor_exception: {str(exc)}"
                })

    # ğŸ“Š ì „ì²´ ê²°ê³¼ ìš”ì•½
    total_elapsed_time = time.time() - total_start_time
    success_count = sum(1 for r in results if r["status"] == "success")
    failed_count = sum(1 for r in results if r["status"] == "failed")
    skipped_count = sum(1 for r in results if r["status"] == "skipped")
    
    logger.info(f"ğŸ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ!")
    logger.info(f"â±ï¸ ì´ ì†Œìš”ì‹œê°„: {total_elapsed_time:.1f}ì´ˆ")
    logger.info(f"ğŸ“Š ê²°ê³¼ ìš”ì•½: ì„±ê³µ {success_count}ê°œ, ì‹¤íŒ¨ {failed_count}ê°œ, ìŠ¤í‚µ {skipped_count}ê°œ")
    
    # ê° ì¹´í…Œê³ ë¦¬ë³„ ìƒì„¸ ê²°ê³¼ ë¡œê·¸
    for result in results:
        status_emoji = {"success": "âœ…", "failed": "âŒ", "skipped": "â­ï¸"}.get(result["status"], "â“") 
        logger.info(f"{status_emoji} {result['category']}: {result['status']}")
        if "reason" in result:
            logger.info(f"   â””â”€ ì‚¬ìœ : {result['reason']}")

    return results