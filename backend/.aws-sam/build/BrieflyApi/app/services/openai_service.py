# app/services/openai_service.py

import os
import openai
import numpy as np   # ì„ë² ë”© ê³„ì‚°ìš©
import logging

openai.api_key = os.getenv("OPENAI_API_KEY")
MODEL_NAME = os.getenv("OPENAI_MODEL", "gpt-4o-mini")  # ğŸ”§ í™˜ê²½ë³€ìˆ˜ë¡œ ëª¨ë¸ ì„¤ì • ê°€ëŠ¥

logger = logging.getLogger(__name__)

def get_embedding(text: str) -> list:
    """
    í…ìŠ¤íŠ¸ì˜ ì„ë² ë”© ë²¡í„°ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
    """
    try:
        res = openai.embeddings.create(
            input=[text],
            model="text-embedding-3-small"
        )
        return res.data[0].embedding
    except openai.RateLimitError as e:
        logger.warning(f"âš ï¸ OpenAI Rate Limit ì´ˆê³¼: {e}")
        return []
    except openai.APIError as e:
        logger.warning(f"âš ï¸ OpenAI API ì˜¤ë¥˜: {e}")
        return []
    except openai.AuthenticationError as e:
        logger.warning(f"âš ï¸ OpenAI ì¸ì¦ ì˜¤ë¥˜: {e}")
        return []
    except Exception as e:
        logger.warning(f"âš ï¸ ì„ë² ë”© ìƒì„± ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: {e}")
        return []

def cosine_similarity(vec1, vec2):
    """
    ë‘ ë²¡í„° ê°„ì˜ ì½”ì‚¬ì¸ ìœ ì‚¬ë„ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.
    """
    try:
        if not vec1 or not vec2:
            return 0.0
        return np.dot(vec1, vec2) / (np.linalg.norm(vec1) * np.linalg.norm(vec2))
    except (ValueError, ZeroDivisionError, np.linalg.LinAlgError) as e:
        logger.warning(f"âš ï¸ ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚° ì˜¤ë¥˜: {e}")
        return 0.0
    except Exception as e:
        logger.warning(f"âš ï¸ ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: {e}")
        return 0.0

def cluster_similar_texts(texts, threshold=0.75):
    """
    ìœ ì‚¬í•œ í…ìŠ¤íŠ¸ë“¤ì„ í´ëŸ¬ìŠ¤í„°ë§í•˜ì—¬ ì¤‘ë³µ ë‚´ìš©ì„ ê·¸ë£¹í™”í•©ë‹ˆë‹¤.
    """
    if len(texts) <= 1:
        return [texts]
    
    try:
        logger.info(f"ğŸ”„ {len(texts)}ê°œ í…ìŠ¤íŠ¸ í´ëŸ¬ìŠ¤í„°ë§ ì‹œì‘...")
        embeddings = []
        
        # ì„ë² ë”© ìƒì„± (ì‹¤íŒ¨í•œ ê²ƒë“¤ì€ ì œì™¸)
        valid_texts = []
        for i, text in enumerate(texts):
            emb = get_embedding(text[:1000])  # ğŸ”§ í† í° ì œí•œ: 1500ì â†’ 1000ì
            if emb:
                embeddings.append(emb)
                valid_texts.append(text)
        
        if len(embeddings) <= 1:
            return [valid_texts]
            
        clusters = []
        for idx, emb in enumerate(embeddings):
            added = False
            for cluster in clusters:
                if cosine_similarity(emb, cluster['embedding']) > threshold:
                    cluster['indices'].append(idx)
                    added = True
                    break
            if not added:
                clusters.append({'embedding': emb, 'indices': [idx]})
        
        # í´ëŸ¬ìŠ¤í„°ë³„ë¡œ í…ìŠ¤íŠ¸ ê·¸ë£¹í™”
        grouped = [[valid_texts[i] for i in c['indices']] for c in clusters]
        logger.info(f"âœ… {len(texts)}ê°œ â†’ {len(grouped)}ê°œ í´ëŸ¬ìŠ¤í„°ë¡œ ê·¸ë£¹í™”")
        return grouped
        
    except MemoryError as e:
        logger.warning(f"âš ï¸ ë©”ëª¨ë¦¬ ë¶€ì¡±ìœ¼ë¡œ í´ëŸ¬ìŠ¤í„°ë§ ì‹¤íŒ¨: {e}")
        return [texts]
    except (ValueError, TypeError) as e:
        logger.warning(f"âš ï¸ ë°ì´í„° í˜•ì‹ ì˜¤ë¥˜ë¡œ í´ëŸ¬ìŠ¤í„°ë§ ì‹¤íŒ¨: {e}")
        return [texts]
    except Exception as e:
        logger.warning(f"âš ï¸ í´ëŸ¬ìŠ¤í„°ë§ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜, ì›ë³¸ ë°˜í™˜: {e}")
        return [texts]

def summarize_group(texts: list, category: str) -> str:
    """
    í´ëŸ¬ìŠ¤í„°ëœ ìœ ì‚¬ ê¸°ì‚¬ë“¤ì„ í•˜ë‚˜ì˜ ìš”ì•½ìœ¼ë¡œ í†µí•©í•©ë‹ˆë‹¤.
    """
    if len(texts) == 1:
        return texts[0]
    
    # ğŸ”§ í† í° ìµœì í™”: ê° í…ìŠ¤íŠ¸ ê¸¸ì´ ì œí•œ
    limited_texts = [text[:800] for text in texts]  # ê° ê¸°ì‚¬ 800ìë¡œ ì œí•œ
        
    prompt = (
        f"ë‹¤ìŒì€ '{category}' ë¶„ì•¼ì—ì„œ ë¹„ìŠ·í•œ ë‚´ìš©ì˜ ë‰´ìŠ¤ ê¸°ì‚¬ë“¤ì…ë‹ˆë‹¤. "
        f"ì¤‘ë³µë˜ëŠ” ë‚´ìš©ì„ ì œê±°í•˜ê³ , í•µì‹¬ ì •ë³´ë§Œì„ ë‹´ì•„ "
        f"í•˜ë‚˜ì˜ ìì—°ìŠ¤ëŸ¬ìš´ ìš”ì•½(500ì~700ì)ìœ¼ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”.\n\n"
        + "\n\n".join(limited_texts)
    )
    
    try:
        response = openai.chat.completions.create(
            model=MODEL_NAME,  # ğŸ”§ í™˜ê²½ë³€ìˆ˜ ëª¨ë¸ ì‚¬ìš©
            messages=[{"role": "user", "content": prompt}],
            temperature=0.7,
            max_tokens=700  # ğŸ”§ í† í° ì œí•œ: 900 â†’ 700
        )
        return response.choices[0].message.content.strip()
    except openai.RateLimitError as e:
        logger.warning(f"âš ï¸ OpenAI Rate Limit ì´ˆê³¼ (ê·¸ë£¹ ìš”ì•½): {e}")
        return texts[0]
    except openai.APIError as e:
        logger.warning(f"âš ï¸ OpenAI API ì˜¤ë¥˜ (ê·¸ë£¹ ìš”ì•½): {e}")
        return texts[0]
    except openai.AuthenticationError as e:
        logger.warning(f"âš ï¸ OpenAI ì¸ì¦ ì˜¤ë¥˜ (ê·¸ë£¹ ìš”ì•½): {e}")
        return texts[0]
    except Exception as e:
        logger.warning(f"âš ï¸ ê·¸ë£¹ ìš”ì•½ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: {e}")
        return texts[0]  # ì‹¤íŒ¨ì‹œ ì²« ë²ˆì§¸ í…ìŠ¤íŠ¸ ë°˜í™˜

def summarize_articles(texts: list[str], category: str) -> str:
    """
    GPT-4o-minië¥¼ ì‚¬ìš©í•˜ì—¬ ì—¬ëŸ¬ ê°œì˜ ë‰´ìŠ¤ ìš”ì•½ì„ ë°”íƒ•ìœ¼ë¡œ
    í•˜ë‚˜ì˜ íë¦„ì„ ê°€ì§„ íŒŸìºìŠ¤íŠ¸ ëŒ€ë³¸ì„ ìƒì„±í•©ë‹ˆë‹¤.
    """
    
    # ğŸ”„ [2ì°¨ í´ëŸ¬ìŠ¤í„°ë§] GPT ìš”ì•½ë¬¸ ê¸°ë°˜ ì˜ë¯¸ì  ì¤‘ë³µ ì œê±°
    try:
        if len(texts) > 5:  # 5ê°œ ì´ìƒì¼ ë•Œë§Œ í´ëŸ¬ìŠ¤í„°ë§ ì ìš©
            logger.info(f"ğŸ”„ 2ì°¨ í´ëŸ¬ìŠ¤í„°ë§ ì‹œì‘: {len(texts)}ê°œ ìš”ì•½ë¬¸")
            clustered_groups = cluster_similar_texts(texts, threshold=0.75)
            
            # ê° í´ëŸ¬ìŠ¤í„°ë¥¼ í•˜ë‚˜ì˜ ìš”ì•½ìœ¼ë¡œ í†µí•©
            consolidated_texts = []
            for group_idx, group in enumerate(clustered_groups):
                if len(group) > 1:
                    # ì—¬ëŸ¬ ìœ ì‚¬ ìš”ì•½ë¬¸ì„ í•˜ë‚˜ë¡œ í†µí•©
                    try:
                        summary = summarize_group(group, category)
                        consolidated_texts.append(summary)
                        logger.info(f"ğŸ“Š 2ì°¨ ê·¸ë£¹ #{group_idx+1}: {len(group)}ê°œ ìš”ì•½ â†’ í†µí•© ({len(summary)}ì)")
                    except Exception as e:
                        logger.warning(f"âš ï¸ 2ì°¨ ê·¸ë£¹ #{group_idx+1} ìš”ì•½ ì‹¤íŒ¨, ì²« ë²ˆì§¸ ì‚¬ìš©: {e}")
                        consolidated_texts.append(group[0][:1000])  # ğŸ”§ ê¸¸ì´ ì œí•œ
                else:
                    # ë‹¨ì¼ ìš”ì•½ì€ ê·¸ëŒ€ë¡œ ì‚¬ìš© (ê¸¸ì´ ì œí•œ)
                    consolidated_texts.append(group[0][:1000])  # ğŸ”§ ë‹¨ì¼ ê¸°ì‚¬ë„ 1000ìë¡œ ì œí•œ
                    logger.info(f"ğŸ“„ 2ì°¨ ê·¸ë£¹ #{group_idx+1}: ë‹¨ì¼ ìš”ì•½ ({len(group[0][:1000])}ì)")
            
            final_texts = consolidated_texts
            logger.info(f"âœ… 2ì°¨ í´ëŸ¬ìŠ¤í„°ë§ ì™„ë£Œ: {len(texts)}ê°œ â†’ {len(final_texts)}ê°œ ê·¸ë£¹")
        else:
            # ğŸ”§ í´ëŸ¬ìŠ¤í„°ë§ ì•ˆí•  ë•Œë„ ê¸¸ì´ ì œí•œ
            final_texts = [text[:1000] for text in texts]
            logger.info(f"ğŸ“ 2ì°¨ í´ëŸ¬ìŠ¤í„°ë§ ìƒëµ, ì›ë³¸ ìš”ì•½ ìˆ˜: {len(final_texts)}")
            
    except Exception as e:
        logger.warning(f"âš ï¸ 2ì°¨ í´ëŸ¬ìŠ¤í„°ë§ ê³¼ì • ì‹¤íŒ¨, ì›ë³¸ ì‚¬ìš©: {e}")
        final_texts = [text[:1000] for text in texts]  # ğŸ”§ ì‹¤íŒ¨ì‹œì—ë„ ê¸¸ì´ ì œí•œ

    # ğŸ™ï¸ ìµœì¢… íŒŸìºìŠ¤íŠ¸ ëŒ€ë³¸ ìƒì„±
    prompt = (
        f"ë‹¹ì‹ ì€ ì§€ì ì´ë©´ì„œë„ ì¹œê·¼í•œ ë§íˆ¬ë¡œ ì •ë³´ë¥¼ ì „ë‹¬í•˜ëŠ” í”„ë¡œ íŒŸìºìŠ¤íŠ¸ ì§„í–‰ìì…ë‹ˆë‹¤. "
        f"ì²­ì·¨ìëŠ” '{category}' ë¶„ì•¼ì— ê´€ì‹¬ì€ ìˆì§€ë§Œ ì „ë¬¸ê°€ëŠ” ì•„ë‹Œ ì¼ë°˜ ëŒ€ì¤‘ì…ë‹ˆë‹¤.\n\n"
        "ë‹¤ìŒì€ í•´ë‹¹ ì¹´í…Œê³ ë¦¬ì˜ ì˜¤ëŠ˜ì˜ ì£¼ìš” ë‰´ìŠ¤ ë³¸ë¬¸ ìš”ì•½ ë¦¬ìŠ¤íŠ¸ì…ë‹ˆë‹¤:\n\n"
        "{{ë‰´ìŠ¤_ìš”ì•½_ë¦¬ìŠ¤íŠ¸}}\n\n"
        "ê° ê¸°ì‚¬ì˜ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ì²­ì·¨ìì—ê²Œ ì „ë‹¬ë ¥ ìˆê²Œ êµ¬ì„±ëœ íŒŸìºìŠ¤íŠ¸ ëŒ€ë³¸ì„ ì‘ì„±í•´ì£¼ì„¸ìš”. "
        "ìŠ¤í¬ë¦½íŠ¸ëŠ” í•˜ë‚˜ì˜ ì´ì•¼ê¸° íë¦„ì²˜ëŸ¼ ìì—°ìŠ¤ëŸ½ê²Œ ì´ì–´ì§€ë„ë¡ í•˜ë©°, ì „ì²´ ë¶„ëŸ‰ì€ **ë°˜ë“œì‹œ ìµœì†Œ 1800ì ì´ìƒ**ì´ì–´ì•¼ í•©ë‹ˆë‹¤.\n\n"
        "**ê¸¸ì´ ìš”êµ¬ì‚¬í•­:**\n"
        "- ìµœì†Œ 1800ì ì´ìƒ (í•„ìˆ˜)\n"
        "- ìµœëŒ€ 2200ì ì´í•˜ (ê¶Œì¥)\n"
        "- ë§Œì•½ 1800ìì— ë¯¸ë‹¬í•˜ë©´ ê° ì£¼ì œì— ëŒ€í•œ ì„¤ëª…ì„ ë” ìì„¸íˆ í’€ì–´ì¨ ì£¼ì„¸ìš”\n\n"
        "**ì‘ì„± ì¡°ê±´:**\n"
        "- ë§í•˜ë“¯ ìì—°ìŠ¤ëŸ½ê³  ë”°ëœ»í•œ ì§„í–‰ í†¤ ìœ ì§€\n"
        "- ë‰´ìŠ¤ ê¸°ì‚¬ë“¤ì„ ë‹¨ìˆœ ë‚˜ì—´í•˜ì§€ ë§ê³ , ì£¼ì œ ê°„ ì—°ê²° ë¬¸ì¥ì„ í™œìš©í•´ í•˜ë‚˜ì˜ íë¦„ìœ¼ë¡œ ì—°ê²°\n"
        f"- ë„ì…ë¶€ì—ëŠ” 'ì˜¤ëŠ˜ {category} ë¶„ì•¼ì—ì„œëŠ” ì´ëŸ° ì´ìŠˆë“¤ì´ ìˆì—ˆìŠµë‹ˆë‹¤.'ì™€ ê°™ì€ ë©˜íŠ¸ í¬í•¨\n"
        "- ê° ë‰´ìŠ¤ í•­ëª©ë§ˆë‹¤ ì¶©ë¶„í•œ ì„¤ëª…ê³¼ ë¶„ì„ì„ í¬í•¨í•˜ì—¬ ìƒì„¸íˆ ë‹¤ë¤„ì£¼ì„¸ìš”\n"
        "- ë‰´ìŠ¤ì˜ ë°°ê²½, ì˜ë¯¸, íŒŒê¸‰íš¨ê³¼ ë“±ì„ í¬í•¨í•˜ì—¬ ì‹¬ë„ ìˆê²Œ ì„¤ëª…í•´ì£¼ì„¸ìš”\n"
        "- ë§ˆë¬´ë¦¬ì—ì„œëŠ” ì¢…í•©ì ì¸ ìš”ì•½ê³¼ ì²­ì·¨ìì—ê²Œ ìƒê°í•  ê±°ë¦¬ë¥¼ ë‚¨ê¸°ëŠ” ë§ë¡œ ëë‚´ê¸°\n"
        "- ë¬¸ë‹¨ êµ¬ë¶„ê³¼ ë¦¬ë“¬ì„ ê³ ë ¤í•˜ì—¬ ì‹¤ì œ ìŒì„±ìœ¼ë¡œ ì½ê¸° ì¢‹ê²Œ êµ¬ì„±\n"
        "- ì¶©ë¶„í•œ ê¸¸ì´ë¥¼ í™•ë³´í•˜ê¸° ìœ„í•´ ì„¤ëª…ì„ í’ë¶€í•˜ê²Œ í•´ì£¼ì„¸ìš”\n\n"
        "**ì¤‘ìš”:** ìµœì¢… ëŒ€ë³¸ì´ 1800ì ë¯¸ë§Œì´ë©´ ì•ˆ ë©ë‹ˆë‹¤. ê° ì£¼ì œë¥¼ ì¶©ë¶„íˆ ìì„¸íˆ ì„¤ëª…í•˜ì—¬ ëª©í‘œ ê¸¸ì´ë¥¼ ë‹¬ì„±í•´ì£¼ì„¸ìš”.\n\n"
        "Take a deep breath and let's work this out in a step by step way to be sure we have the right answer."
    )

    # ë‰´ìŠ¤ ìš”ì•½ ë¦¬ìŠ¤íŠ¸ë¥¼ ë¬¸ìì—´ë¡œ ì •ë¦¬
    article_list = "\n".join([f"- {text}" for text in final_texts])
    context = prompt.replace("{{ë‰´ìŠ¤_ìš”ì•½_ë¦¬ìŠ¤íŠ¸}}", article_list)

    try:
        response = openai.chat.completions.create(
            model=MODEL_NAME,  # ğŸ”§ í™˜ê²½ë³€ìˆ˜ ëª¨ë¸ ì‚¬ìš©
            messages=[{"role": "user", "content": context}],
            temperature=0.7,
            max_tokens=2000  # ğŸ”§ í† í° ì œí•œ: 2200 â†’ 2000
        )
        
        result = response.choices[0].message.content.strip()
        logger.info(f"ğŸ“ ìƒì„±ëœ ëŒ€ë³¸ ê¸¸ì´: {len(result)}ì (ëª¨ë¸: {MODEL_NAME})")  # ğŸ”§ ì‚¬ìš© ëª¨ë¸ ë¡œê·¸ ì¶”ê°€
        return result
        
    except openai.RateLimitError as e:
        logger.warning(f"âš ï¸ OpenAI Rate Limit ì´ˆê³¼ (ëŒ€ë³¸ ìƒì„±): {e}")
        return f"ì˜¤ëŠ˜ {category} ë¶„ì•¼ì˜ ì£¼ìš” ì†Œì‹ë“¤ì„ ì „í•´ë“œë ¸ìŠµë‹ˆë‹¤."
    except openai.APIError as e:
        logger.warning(f"âš ï¸ OpenAI API ì˜¤ë¥˜ (ëŒ€ë³¸ ìƒì„±): {e}")
        return f"ì˜¤ëŠ˜ {category} ë¶„ì•¼ì˜ ì£¼ìš” ì†Œì‹ë“¤ì„ ì „í•´ë“œë ¸ìŠµë‹ˆë‹¤."
    except openai.AuthenticationError as e:
        logger.warning(f"âš ï¸ OpenAI ì¸ì¦ ì˜¤ë¥˜ (ëŒ€ë³¸ ìƒì„±): {e}")
        return f"ì˜¤ëŠ˜ {category} ë¶„ì•¼ì˜ ì£¼ìš” ì†Œì‹ë“¤ì„ ì „í•´ë“œë ¸ìŠµë‹ˆë‹¤."
    except Exception as e:
        logger.warning(f"âš ï¸ ëŒ€ë³¸ ìƒì„± ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: {e}")
        return f"ì˜¤ëŠ˜ {category} ë¶„ì•¼ì˜ ì£¼ìš” ì†Œì‹ë“¤ì„ ì „í•´ë“œë ¸ìŠµë‹ˆë‹¤."